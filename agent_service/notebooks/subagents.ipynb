{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb867926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\fuse\\Csa\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7917169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf1eea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional, TypedDict, Annotated\n",
    "from operator import add\n",
    "\n",
    "# Define State\n",
    "class State(TypedDict):\n",
    "    query: str\n",
    "    chat_history: List[Dict[str, str]]  # List of {\"user\": ..., \"bot\": ...}\n",
    "    query_types: Optional[List[Dict]]  # Will be filled by orchestrator\n",
    "    subagent_outputs: Annotated[list, add]\n",
    "    final_response: Optional[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dbd374d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Parameters(BaseModel):\n",
    "    search: Optional[str] = None\n",
    "    type: Optional[Literal[\"veg\", \"non-veg\"]] = None\n",
    "    price_min: Optional[float] = None\n",
    "    price_max: Optional[float] = None\n",
    "    topic: Optional[str] = None\n",
    "\n",
    "class QueryTypeItem(BaseModel):\n",
    "    type: Literal[\"menu\", \"info\", \"escalation\", \"chitchat\", \"ambiguous\"]\n",
    "    parameters: Optional[Parameters] = None\n",
    "    clarification: Optional[str] = None\n",
    "\n",
    "class OrchestratorOutput(BaseModel):\n",
    "    query_types: List[QueryTypeItem]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a08b38",
   "metadata": {},
   "source": [
    "### Orchestrator stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f5f43c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCHESTRATOR_PROMPT = \"\"\"SYSTEM:\n",
    "You are a restaurant assistant agent. Your task is to analyze a user query, classify its intent, and extract menu parameters if applicable. Do not answer the query; only classify and extract.\n",
    "\n",
    "Classify the query into one or more of these types:\n",
    "- menu: User wants menu details (dish names, type, price range, etc.)\n",
    "- info: User asks about restaurant details (opening hours, location, contact, etc.)\n",
    "- escalation: User explicitly requests human help or clearly requires it.\n",
    "- chitchat: Casual or irrelevant conversation not needing a subagent.\n",
    "- ambiguous: Query is unclear or missing key details. Provide a single clarifying question.\n",
    "\n",
    "Menu parameters (for type=\"menu\"):\n",
    "- search: dish name or keyword\n",
    "- type: \"veg\" or \"non-veg\"\n",
    "- price_min / price_max: numeric values, if mentioned.\n",
    "\n",
    "Info queries:\n",
    "- Extract the concerned topic (e.g. \"opening hours\", \"address\", \"delivery options\") into `parameters` as { \"topic\": \"<string>\" }.\n",
    "\n",
    "Special instructions:\n",
    "- A query may have multiple types.\n",
    "- Only ambiguous queries have a clarifying question.\n",
    "- Always populate `parameters.search` for menu intents with any descriptive text from the user's query that could help search: single words, adjectives, adjective+noun phrases, quoted phrases, situational cues (e.g., \"for cold weather\", \"spicy\", \"breakfast\", \"kid-friendly\"). Do not try to normalize or expand these — just extract the phrase(s) verbatim (trimmed). If there are multiple useful phrases, join them with a comma in `search` (e.g., \"spicy, cold weather\").\n",
    "- But if you detect a menu intent but cannot extract at least one useful menu parameter (search, type, price_min, or price_max), like \"food\", \"something\" etc then mark that intent as \"ambiguous\" and provide a single concise clarifying question asking for the missing detail (for example: \"Do you prefer veg or non-veg, or do you want recommendations?\").\n",
    "- Normalize non-vegetarian types to \"non-veg\".\n",
    "- Return data that matches the structured schema provided by the system.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1d228523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "import json\n",
    "\n",
    "orchestrator_llm = llm.with_structured_output(OrchestratorOutput)\n",
    "\n",
    "# Orchestrator Node\n",
    "def orchestrator_node(state: State):\n",
    "    \"\"\"Classify user query and extract menu parameters for subagents.\"\"\"\n",
    "\n",
    "    # Construct LLM messages\n",
    "    messages = [\n",
    "        SystemMessage(content=ORCHESTRATOR_PROMPT),\n",
    "        HumanMessage(content=f\"Chat history:{state[\"chat_history\"]}\"),\n",
    "        HumanMessage(content=state[\"query\"])\n",
    "    ]\n",
    "\n",
    "    # Call the LLM (replace `llm` with your LangChain/LLM client)\n",
    "    parsed: OrchestratorOutput = orchestrator_llm.invoke(messages)  # Should return JSON string\n",
    "\n",
    "    state[\"query_types\"] = parsed.model_dump()[\"query_types\"]\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fc306b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'menu', 'parameters': {'search': 'pizza, chicken', 'type': 'non-veg', 'price_min': None, 'price_max': None, 'topic': None}, 'clarification': None}, {'type': 'info', 'parameters': {'search': None, 'type': None, 'price_min': None, 'price_max': None, 'topic': 'opening hours'}, 'clarification': None}]\n"
     ]
    }
   ],
   "source": [
    "test_state = {\n",
    "    \"query\": \"wht kind of pizza you got maybe with chicken also are you open at 5pm\",\n",
    "    \"chat_history\": [\n",
    "        {\"user\": \"Hi\", \"bot\": \"Hello! How can I help you today?\"},\n",
    "        {\"user\": \"I want to know your menu.\", \"bot\": \"Sure, what type of dishes are you interested in?\"}\n",
    "    ]\n",
    "}\n",
    "resp = orchestrator_node(test_state)\n",
    "print(resp['query_types'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ad9a1a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'wht kind of pizza you got maybe with chicken also are you open at 5pm',\n",
       " 'chat_history': [{'user': 'Hi', 'bot': 'Hello! How can I help you today?'},\n",
       "  {'user': 'I want to know your menu.',\n",
       "   'bot': 'Sure, what type of dishes are you interested in?'}],\n",
       " 'query_types': [{'type': 'menu',\n",
       "   'parameters': {'search': 'pizza, chicken',\n",
       "    'type': 'non-veg',\n",
       "    'price_min': None,\n",
       "    'price_max': None,\n",
       "    'topic': None},\n",
       "   'clarification': None},\n",
       "  {'type': 'info',\n",
       "   'parameters': {'search': None,\n",
       "    'type': None,\n",
       "    'price_min': None,\n",
       "    'price_max': None,\n",
       "    'topic': 'opening hours'},\n",
       "   'clarification': None}]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ba2de3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search': 'pizza, chicken',\n",
       " 'type': 'non-veg',\n",
       " 'price_min': None,\n",
       " 'price_max': None,\n",
       " 'topic': None}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp['query_types'][0]['parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "783a1261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Send(node='menu_agent', arg={'search': 'pizza, chicken', 'type': 'non-veg'}),\n",
       " Send(node='info_agent', arg={'topic': 'opening hours'})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_params = assign_subagents(resp)\n",
    "filtered_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db90a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d37e4783",
   "metadata": {},
   "source": [
    "### Menu agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e233baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests\n",
    "\n",
    "def menu_agent(state: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieves restaurant menu items based on the provided criteria\n",
    "    and returns in the structured format for subagent aggregation.\n",
    "    \"\"\"\n",
    "    menu_params = state.get(\"params\", {})\n",
    "    base_url = os.getenv(\"BASE_URL\")\n",
    "    items_url = base_url + \"/items\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(items_url, params=menu_params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        menu_data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        menu_data = {\"error\": str(e)}\n",
    "\n",
    "    # Return wrapped in subagent_outputs for operator.add merging\n",
    "    return {\n",
    "        \"subagent_outputs\": [\n",
    "            {\n",
    "                \"type\": \"menu\",\n",
    "                \"parameters\": menu_params,  # only non-None params if you want\n",
    "                \"output\": menu_data\n",
    "            }\n",
    "        ]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de36c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = menu_agent(resp['query_types'][0]['parameters'])\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288766e",
   "metadata": {},
   "source": [
    "### Info agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "485aaced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests\n",
    "\n",
    "def info_agent(state:dict) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieves restaurant knowledge base information based on a user query.\n",
    "    \"\"\"\n",
    "    info_params = state.get(\"params\", {})\n",
    "    query_str = info_params.get(\"topic\", \"\")\n",
    "\n",
    "    base_url = os.getenv(\"BASE_URL\")\n",
    "    kb_url = base_url + \"/knowledge/semantic-search\"\n",
    "    params = {\n",
    "        \"search\": query_str\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(kb_url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        info_data= response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error calling backend: {e}\")\n",
    "        info_data ={\"error\": str(e)}\n",
    "    \n",
    "    return {\n",
    "        \"subagent_outputs\": [\n",
    "            {\n",
    "                \"type\": \"menu\",\n",
    "                \"parameters\": info_params,  # only non-None params if you want\n",
    "                \"output\": info_data\n",
    "            }\n",
    "        ]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed6209",
   "metadata": {},
   "source": [
    "### Synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "866f2508",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNTHESIZER_PROMPT = \"\"\"SYSTEM:\n",
    "You are a restaurant assistant responsible for generating the final, user-facing response.\n",
    "You are given:\n",
    "\n",
    "1. The **user query**.\n",
    "2. The **recent chat history** between the user and the bot.\n",
    "3. The **outputs from subagents**, each containing:\n",
    "   - type: the subagent type (menu, info, etc.)\n",
    "   - parameters: the input parameters used for the subagent\n",
    "   - output: the result returned by that subagent\n",
    "\n",
    "Your task:\n",
    "\n",
    "1. Produce a coherent, human-like response using **only the subagent outputs** and memory results if available.\n",
    "2. Handle different scenarios:\n",
    "\n",
    "   a. **Direct match**: If the subagent output fully satisfies the query, use it in your answer.\n",
    "   \n",
    "   b. **Partial match**: If the output partially satisfies the query:\n",
    "      - Highlight what matches\n",
    "      - Ask a concise clarifying question if necessary\n",
    "   \n",
    "   c. **Too verbose / many items** (e.g., menu lists):\n",
    "      - Summarize the categories or main items\n",
    "      - Ask the user for a preference to provide detailed results\n",
    "   \n",
    "   d. **No relevant information**: Politely inform the user that the information is unavailable.\n",
    "   \n",
    "3. Always ensure that:\n",
    "   - Responses are concise (1–3 sentences) unless a clarifying question is needed.\n",
    "   - Only **one clarifying question** is asked at a time.\n",
    "   - Do **not hallucinate**; rely only on the subagent outputs or memory.\n",
    "   - Combine multiple subagent outputs if the query involves more than one type (e.g., menu + info).\n",
    "\n",
    "Output format (JSON):\n",
    "{\n",
    "  \"final_answer\": \"string\"        # The coherent response or clarification\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a88845de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from typing import Dict\n",
    "\n",
    "# Assuming you have a structured output model like this:\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class SynthesizerOutput(BaseModel):\n",
    "    final_answer: str  # Can be an answer or a clarifying question\n",
    "\n",
    "# Wrap the LLM\n",
    "synthesizer_llm = llm.with_structured_output(SynthesizerOutput)\n",
    "\n",
    "# Synthesizer Node\n",
    "def synthesizer_node(state: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Generate a coherent response from subagent outputs.\n",
    "    \"\"\"\n",
    "    user_query = state[\"query\"]\n",
    "    chat_history = state.get(\"chat_history\", [])\n",
    "    subagent_outputs = state.get(\"subagent_outputs\", [])\n",
    "\n",
    "    # Format chat history\n",
    "    chat_str = \"\\n\".join([f\"User: {c['user']}\\nBot: {c['bot']}\" for c in chat_history])\n",
    "\n",
    "    # Format subagent outputs\n",
    "    subagent_str = \"\"\n",
    "    for sa in subagent_outputs:\n",
    "        sa_type = sa[\"type\"]\n",
    "        sa_params = sa.get(\"parameters\", {})\n",
    "        sa_output = sa.get(\"output\")\n",
    "        subagent_str += f\"\\n\\n---\\nSubagent type: {sa_type}\\nParameters: {sa_params}\\nOutput: {sa_output}\"\n",
    "\n",
    "    # Construct messages using the separate prompt\n",
    "    messages = [\n",
    "        SystemMessage(content=SYNTHESIZER_PROMPT),\n",
    "        HumanMessage(content=f\"User query: {user_query}\\nChat history:\\n{chat_str}\\nSubagent outputs:\\n{subagent_str}\")\n",
    "    ]\n",
    "\n",
    "    # Call the LLM\n",
    "    parsed: SynthesizerOutput = synthesizer_llm.invoke(messages)\n",
    "    # parsed = llm.invoke(messages)\n",
    "\n",
    "    # Store in state\n",
    "    state[\"final_response\"] = parsed.model_dump()[\"final_answer\"]\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd035571",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_state = {\n",
    "    \"query\": \"wht kind of dumpling you got maybe with chicken also are you open at 5pm\",\n",
    "    \"chat_history\": [\n",
    "        {\"user\": \"Hi\", \"bot\": \"Hello! How can I help you today?\"},\n",
    "        {\"user\": \"I want to know your menu.\", \"bot\": \"Sure, what type of dishes are you interested in?\"}\n",
    "    ],\n",
    "    \"subagent_outputs\": [\n",
    "        {\n",
    "            \"type\": \"menu\",\n",
    "            \"parameters\": {'search': 'dumpling, chicken','type': 'non-veg','price_min': None,'price_max': None,'topic': None},\n",
    "            \"output\": [\n",
    "                {\"name\": \"Spicy Paneer Curry\", \"type\": \"veg\", \"price\": 350},\n",
    "                {\"name\": \"Spicy Chicken Momo\", \"type\": \"non-veg\", \"price\": 450}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"info\",\n",
    "            \"parameters\": {'topic': 'opening hours'},\n",
    "            \"output\": \"We are located at Lazimpat, Kathmandu. The opening hours is 6 am to 4pm.\"\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8240cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have Spicy Chicken Momo on our menu. Regarding your query about opening hours, we are open from 6 AM to 4 PM, so we are not open at 5 PM.\n"
     ]
    }
   ],
   "source": [
    "# Call the node\n",
    "updated_state = synthesizer_node(test_state)\n",
    "\n",
    "# Check the final response\n",
    "print(updated_state[\"final_response\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7e928b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Send\n",
    "\n",
    "def assign_subagents(state: State):\n",
    "    sends = []\n",
    "\n",
    "    for qt in state.get(\"query_types\", []):\n",
    "        if qt[\"type\"] == \"menu\":\n",
    "            sends.append(Send(\"menu_agent\", {\"params\": {k: v for k, v in qt[\"parameters\"].items() if v is not None}}))\n",
    "        elif qt[\"type\"] == \"info\":\n",
    "            sends.append(Send(\"info_agent\", {\"params\": {k: v for k, v in qt[\"parameters\"].items() if v is not None}}))\n",
    "        elif qt[\"type\"] == \"escalation\":\n",
    "            sends.append(Send(\"escalation_agent\", {\"params\": qt.get(\"parameters\", {})}))\n",
    "        elif qt[\"type\"] == \"ambiguous\":\n",
    "            # inject synthetic chitchat output for synthesizer, no Send required\n",
    "            state.setdefault(\"subagent_outputs\", []).append({\n",
    "                \"type\": \"chitchat\",\n",
    "                \"parameters\": {},\n",
    "                \"output\": qt[\"clarification\"]\n",
    "            })\n",
    "        elif qt[\"type\"] == \"chitchat\":\n",
    "            # inject synthetic chitchat output for synthesizer, no Send required\n",
    "            state.setdefault(\"subagent_outputs\", []).append({\n",
    "                \"type\": \"chitchat\",\n",
    "                \"parameters\": {},\n",
    "                \"output\": None\n",
    "            })\n",
    "\n",
    "    # If no subagents were scheduled, explicitly tell the graph to run synthesizer next\n",
    "    if not sends:\n",
    "        return [Send(\"synthesizer\", {\n",
    "                \"query\": state.get(\"query\"),\n",
    "                \"chat_history\": state.get(\"chat_history\", []),\n",
    "                \"subagent_outputs\": state.get(\"subagent_outputs\", []),\n",
    "                \"memory_results\": state.get(\"memory_results\", [])})]\n",
    "\n",
    "    return sends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "77a11eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build the workflow\n",
    "workflow_builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "workflow_builder.add_node(\"orchestrator\", orchestrator_node)\n",
    "workflow_builder.add_node(\"menu_agent\", menu_agent)\n",
    "workflow_builder.add_node(\"info_agent\", info_agent)\n",
    "# workflow_builder.add_node(\"escalation_agent\", escalation_agent)\n",
    "workflow_builder.add_node(\"synthesizer\", synthesizer_node)\n",
    "\n",
    "# Start edge\n",
    "workflow_builder.add_edge(START, \"orchestrator\")\n",
    "\n",
    "workflow_builder.add_conditional_edges(\"orchestrator\", assign_subagents, [\"menu_agent\", \"info_agent\"])\n",
    "\n",
    "# Collect subagent outputs and send to synthesizer\n",
    "workflow_builder.add_edge(\"menu_agent\", \"synthesizer\")\n",
    "workflow_builder.add_edge(\"info_agent\", \"synthesizer\")\n",
    "# workflow_builder.add_edge(\"escalation_agent\", \"synthesizer\")\n",
    "\n",
    "# End edge\n",
    "workflow_builder.add_edge(\"synthesizer\", END)\n",
    "\n",
    "# Compile workflow\n",
    "restaurant_workflow = workflow_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "394ae623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have several spicy vegetarian options for you, including Veg Spring Rolls and various preparations of Veg Momos like steamed, fried, kothey, jhol, chilly, and sadheko. Would you like to know more about any of these?\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "test_state = {\n",
    "    \"query\": \"lets maybe do veg today\",\n",
    "    \"chat_history\": [\n",
    "        {\"user\": \"Hi\", \"bot\": \"Hello! How can I help you today?\"},\n",
    "        {\"user\": \"do you guys have something hot\", \"bot\": \"Are you looking for a hot drink or a hot dish? Do you have any other preferences, like veg or non-veg?\"},\n",
    "        {\"user\": \"no i mean spicy\", \"bot\": \"We have several spicy options! Some highlights include Spicy Honey Wings, Spicy Buff & Jalapeño Pizza, sadheko buff momo, Chicken Chilly, Chicken Lollipop, Mustang Aloo, and Paneer Chilly. We also have spicy variations of Veg, Buff, and Chicken Momos. Do you have a preference for vegetarian or non-vegetarian, or a specific type of dish you're in the mood for?\"},\n",
    "    ],\n",
    "    \"subagent_outputs\": []  # Start empty\n",
    "}\n",
    "\n",
    "# Invoke the workflow\n",
    "final_state = restaurant_workflow.invoke(test_state)\n",
    "\n",
    "# Final coherent response\n",
    "print(final_state[\"final_response\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
