{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb86f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "392aaa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "llm = ChatOpenAI(\n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url = \"https://openrouter.ai/api/v1\",\n",
    "    model = \"google/gemini-2.5-flash\",\n",
    "    max_completion_tokens=200\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d2e800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTENT_PROMPT = \"\"\"You are an IntentParser for a restaurant assistant.\n",
    "\n",
    "Your job is to:\n",
    "1. Classify the user's message into one or more allowed intents.\n",
    "2. Extract the slots defined for each intent.\n",
    "\n",
    "Allowed intents:\n",
    "- menu — user asks about items, availability, filtering (veg/non-veg/price/type), or search.\n",
    "- knowledge_base — user asks about restaurant policies, FAQs, or other general information.\n",
    "- chit_chat — casual conversation or greetings.\n",
    "- human_escalation — tasks that require human intervention (e.g., placing an order, complaints).\n",
    "- ambiguous — cannot confidently classify.\n",
    "\n",
    "Output format (for storing in state):\n",
    "- Produce a list of tasks, where each task contains:\n",
    "  - intent: one of the allowed intents\n",
    "  - slots: dictionary with relevant keys (see below)\n",
    "  - tool_name: string indicating which tool to call for this intent (menu_tool, kb_tool, or None)\n",
    "  - result: null (to be filled later by tool)\n",
    "\n",
    "Slot schemas:\n",
    "- menu:\n",
    "    - search: string | null\n",
    "    - type: \"veg\" | \"nonveg\" | null\n",
    "    - price_min: number | null\n",
    "    - price_max: number | null\n",
    "- knowledge_base:\n",
    "    - query: string | null\n",
    "- chit_chat:\n",
    "    - slots: empty dictionary {}\n",
    "- human_escalation:\n",
    "    - slots: empty dictionary {}\n",
    "- ambiguous:\n",
    "    - slots: empty dictionary {}\n",
    "\n",
    "Rules:\n",
    "1. For menu intent, always return the same keys (`search`, `type`, `price_min`, `price_max`). Use null if missing.\n",
    "2. For knowledge_base, extract the part of the user query relevant to retrieving data as `query`.\n",
    "3. If multiple distinct intents are present in the user query, split them into separate tasks.\n",
    "4. Include `tool_name` as `\"menu_tool\"` for menu, `\"kb_tool\"` for knowledge_base, and `None` for chit_chat, human_escalation, or ambiguous.\n",
    "5. Always set `result` to null (tools will fill it later).\n",
    "6. Return **only the list of tasks**; do not generate any final answer.\n",
    "\n",
    "Few-shot examples:\n",
    "\n",
    "User: \"Do you have veg pizzas under 12?\"\n",
    "Tasks:\n",
    "[\n",
    "  {\n",
    "    \"intent\": \"menu\",\n",
    "    \"slots\": {\"search\":\"pizza\",\"type\":\"veg\",\"price_min\":null,\"price_max\":12},\n",
    "    \"tool_name\": \"menu_tool\",\n",
    "    \"result\": null\n",
    "  }\n",
    "]\n",
    "\n",
    "User: \"What time do you close on Fridays?\"\n",
    "Tasks:\n",
    "[\n",
    "  {\n",
    "    \"intent\": \"knowledge_base\",\n",
    "    \"slots\": {\"query\":\"closing hours on Fridays\"},\n",
    "    \"tool_name\": \"kb_tool\",\n",
    "    \"result\": null\n",
    "  }\n",
    "]\n",
    "\n",
    "User: \"Hi, how are you?\"\n",
    "Tasks:\n",
    "[\n",
    "  {\n",
    "    \"intent\": \"chit_chat\",\n",
    "    \"slots\": {},\n",
    "    \"tool_name\": null,\n",
    "    \"result\": null\n",
    "  }\n",
    "]\n",
    "\n",
    "User: \"I want to place an order for two burgers.\"\n",
    "Tasks:\n",
    "[\n",
    "  {\n",
    "    \"intent\": \"human_escalation\",\n",
    "    \"slots\": {},\n",
    "    \"tool_name\": null,\n",
    "    \"result\": null\n",
    "  }\n",
    "]\n",
    "\n",
    "User: \"Tell me if you have paneer pizza and your delivery areas.\"\n",
    "Tasks:\n",
    "[\n",
    "  {\n",
    "    \"intent\": \"menu\",\n",
    "    \"slots\": {\"search\":\"pizza\",\"type\":\"veg\",\"price_min\":null,\"price_max\":null},\n",
    "    \"tool_name\": \"menu_tool\",\n",
    "    \"result\": null\n",
    "  },\n",
    "  {\n",
    "    \"intent\": \"knowledge_base\",\n",
    "    \"slots\": {\"query\":\"delivery areas\"},\n",
    "    \"tool_name\": \"kb_tool\",\n",
    "    \"result\": null\n",
    "  }\n",
    "]\n",
    "\n",
    "Final instruction:\n",
    "Respond only with the JSON array of tasks as described above. Do not include commentary or extra text.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da693bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict, Any\n",
    "from langchain.schema import BaseMessage\n",
    "\n",
    "class TaskDict(TypedDict):\n",
    "    intent: str                 # \"menu\", \"knowledge_base\", \"chitchat\", etc.\n",
    "    confidence: float           # model confidence\n",
    "    slots: Dict[str, Any]       # plain dict of slots\n",
    "    result: Any                 # placeholder for tool output (can be None)\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: List[BaseMessage]   # conversation history\n",
    "    tasks: List[TaskDict]         # list of classified tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f78fbb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "class Task(BaseModel):\n",
    "    intent: Literal[\"menu\", \"knowledge_base\", \"chitchat\", \"human_escalation\", \"ambiguous\"]\n",
    "    confidence: float\n",
    "    slots: Dict[str, Any] = {}\n",
    "\n",
    "class IntentOutput(BaseModel):\n",
    "    tasks: List[Task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c01eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, BaseMessage\n",
    "def intent_parser(state: Dict[str, Any], INTENT_PROMPT: str, llm) -> Dict[str, Any]:\n",
    "\n",
    "    # prepare messages (SystemMessage + conversation)\n",
    "    messages: List[BaseMessage] = [SystemMessage(content=INTENT_PROMPT)] + state.get(\"messages\", [])\n",
    "\n",
    "    # get a structured LLM that returns IntentOutput\n",
    "    llm_structured = llm.with_structured_output(IntentOutput)\n",
    "\n",
    "    # invoke model (it returns a parsed IntentOutput instance)\n",
    "    resp = llm_structured.invoke(messages)  # resp is a Pydantic-like object matching IntentOutput\n",
    "\n",
    "    normalized_tasks = []\n",
    "    for t in resp.tasks:\n",
    "        slots = t.slots or {}\n",
    "        normalized_tasks.append({\n",
    "            \"intent\": t.intent,\n",
    "            \"confidence\": float(t.confidence or 0.0),\n",
    "            \"slots\": slots,\n",
    "            \"result\": None\n",
    "        })\n",
    "\n",
    "    # Return minimal state fragment\n",
    "    return {\n",
    "        \"messages\": [resp],      # model message\n",
    "        \"tasks\": normalized_tasks\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69a14065",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"do you guys do anything spicy but it has to be veg and also what time do you guys open\"\n",
    "from langchain.schema import HumanMessage\n",
    "state: State = {\"messages\": [HumanMessage(content=q)],\n",
    "                \"intent\": None, \"confidence\": None, \"slots\": {}}\n",
    "state = intent_parser(state,INTENT_PROMPT, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "855ea3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search': 'spicy', 'type': 'veg', 'price_min': None, 'price_max': None}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[\"tasks\"][0][\"slots\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in state[\"tasks\"]:\n",
    "    if task[\"intent\"] == \"menu\":\n",
    "        task[\"result\"] = menu_tool(task[\"slots\"])\n",
    "    elif task[\"intent\"] == \"knowledge_base\":\n",
    "        task[\"result\"] = kb_tool(task[\"slots\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "970a78f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode, quote_plus\n",
    "def build_menu_uri(base_url: str, s: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Example: base_url = \"https://api.example.com/menu/search\"\n",
    "    Produces: https://api.example.com/menu/search?search=pizza&type=veg&price_max=12\n",
    "    \"\"\"\n",
    "   \n",
    "    params = {}\n",
    "    if s[\"search\"]:\n",
    "        params[\"search\"] = s[\"search\"]\n",
    "    if s[\"type\"]:\n",
    "        params[\"type\"] = s[\"type\"]\n",
    "    if s[\"price_min\"] is not None:\n",
    "        params[\"price_min\"] = str(s[\"price_min\"])\n",
    "    if s[\"price_max\"] is not None:\n",
    "        params[\"price_max\"] = str(s[\"price_max\"])\n",
    "    if params:\n",
    "        return f\"{base_url}?{urlencode(params, quote_via=quote_plus)}\"\n",
    "    return base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82f9bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = build_menu_uri(\"https://api.example.com/menu/search\",state[\"tasks\"][0][\"slots\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91749bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.example.com/menu/search?search=spicy&type=veg'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b691e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
